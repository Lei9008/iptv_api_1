

import asyncio
import aiohttp
import time
import logging
import os
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple, Optional
from typing import List, Tuple

# é…ç½®ç±»
class Config:
    CONCURRENT_LIMIT = 20  # å¹¶å‘é™åˆ¶
    TIMEOUT = 10  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    RETRY_TIMES = 2  # é‡è¯•æ¬¡æ•°
    OUTPUT_DIR = "output"  # è¾“å‡ºç›®å½•
    LOG_FILE = "output/speed_test.log"  # æ—¥å¿—æ–‡ä»¶

config = Config()

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(config.LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ•°æ®ç±»
@dataclass
class SpeedTestResult:
    url: str
    latency: Optional[float] = None  # å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    resolution: Optional[str] = None  # åˆ†è¾¨ç‡
    success: bool = False  # æ˜¯å¦æˆåŠŸ
    error: Optional[str] = None  # é”™è¯¯ä¿¡æ¯
    test_time: float = 0  # æµ‹è¯•æ—¶é—´æˆ³

# é€Ÿåº¦æµ‹è¯•å·¥å…·ç±»
class SpeedTester:
    def __init__(self):
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=config.TIMEOUT))
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def measure_latency(self, url: str, retry_times: int = 3) -> SpeedTestResult:
        """æµ‹é‡å•ä¸ªURLçš„å»¶è¿Ÿå’Œåˆ†è¾¨ç‡"""
        result = SpeedTestResult(url=url, test_time=time.time())
        
        for attempt in range(retry_times):
            try:
                start_time = time.time()
                async with self.session.get(url, headers={"User-Agent": "Mozilla/5.0"}) as response:
                    if response.status == 200:
                        # ç®€å•æµ‹é‡å“åº”æ—¶é—´ä½œä¸ºå»¶è¿Ÿ
                        latency = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                        
                        # å°è¯•ä»å“åº”å¤´æˆ–å†…å®¹ä¸­æå–åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                        resolution = None
                        content_type = response.headers.get("Content-Type", "")
                        if "video" in content_type or "application/vnd.apple.mpegurl" in content_type:
                            # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦è§£æm3u8å†…å®¹è·å–åˆ†è¾¨ç‡
                            resolution = "unknown"
                        
                        result.latency = latency
                        result.resolution = resolution
                        result.success = True
                        logger.info(f"URL: {url} æµ‹è¯•æˆåŠŸï¼Œå»¶è¿Ÿ: {latency:.2f}ms")
                        break
                    else:
                        result.error = f"HTTPçŠ¶æ€ç : {response.status}"
            except Exception as e:
                result.error = str(e)
                logger.warning(f"URL: {url} å°è¯• {attempt+1}/{retry_times} å¤±è´¥: {e}")
                await asyncio.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
        
        return result
    
    async def batch_speed_test(self, urls: List[str]) -> List[SpeedTestResult]:
        """æ‰¹é‡æµ‹é€Ÿï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰"""
        results = []
        semaphore = asyncio.Semaphore(config.CONCURRENT_LIMIT)

        async def worker(url):
            nonlocal results
            async with semaphore:
                result = await self.measure_latency(url, config.RETRY_TIMES)
                results.append(result)

        tasks = [worker(url) for url in urls]
        await asyncio.gather(*tasks)
        
        # æŒ‰å»¶è¿Ÿæ’åºç»“æœï¼ˆå‡åºï¼‰
        return sorted(results, key=lambda x: x.latency if x.latency is not None else float('inf'))

# M3Uæ–‡ä»¶å¤„ç†ç±»
class M3UProcessor:
    @staticmethod
    def parse_m3u(file_path: str) -> List[Tuple[str, str]]:
        """è§£æM3Uæ–‡ä»¶ï¼Œè¿”å›[(åç§°, URL), ...]"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            live_sources = []
            current_name = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('#EXTINF:'):
                    # æå–åç§°
                    name_start = line.find(',') + 1
                    current_name = line[name_start:] if name_start > 0 else "æœªçŸ¥é¢‘é“"
                elif line.startswith('http') and current_name:
                    # æ·»åŠ åˆ°æºåˆ—è¡¨
                    live_sources.append((current_name, line))
                    current_name = None
            
            return live_sources
        except Exception as e:
            logger.error(f"è§£æM3Uæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    @staticmethod
    def generate_m3u(live_sources: List[Tuple[str, str]],output_path: str,category: str = "é»˜è®¤åˆ†ç»„") -> None:  # æ–°å¢ï¼šé¢‘é“åˆ†ç»„åç§°ï¼Œå¯è‡ªå®šä¹‰
    ##ç”Ÿæˆå¸¦æ‰©å±•å­—æ®µçš„M3Uæ–‡ä»¶ï¼ˆå«é¢‘é“logoã€åˆ†ç»„ã€æ—¶é—´æˆ³ã€tvg-idï¼‰
    
    #Args:
        #live_sources: ç›´æ’­æºåˆ—è¡¨ï¼Œå…ƒç´ ä¸º(é¢‘é“åç§°, æ’­æ”¾URL)çš„äºŒå…ƒç»„
        #output_path: M3Uæ–‡ä»¶è¾“å‡ºè·¯å¾„ï¼ˆå¦‚./output/live.m3uï¼‰
        #category: æ‰€æœ‰é¢‘é“çš„åˆ†ç»„åç§°ï¼ˆé»˜è®¤ï¼šé»˜è®¤åˆ†ç»„ï¼‰
    #"""
    # å‰ç½®æ ¡éªŒï¼šç©ºåˆ—è¡¨ç›´æ¥è¿”å›
      if not live_sources:
          logger.warning("ç›´æ’­æºåˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡M3Uæ–‡ä»¶ç”Ÿæˆ")
          return

      try:
        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•
          os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # å†™å…¥M3Uæ–‡ä»¶ï¼ˆä¿®å¤æ‰€æœ‰è¯­æ³•/é€»è¾‘é”™è¯¯ï¼‰
          with open(output_path, 'w', encoding='utf-8') as f:
            # 1. å†™å…¥M3Uå¤´éƒ¨
              f.write('#EXTM3U\n')
            # 2. å†™å…¥æ–‡ä»¶çº§åˆ†ç»„æ ‡é¢˜ï¼ˆå«å½“å‰æ—¶é—´æˆ³ï¼‰
              current_time = time.strftime('%Y-%m-%d %H:%M')
              f.write(f"#EXTINF:-1 group-title="ğŸ•˜ï¸æ›´æ–°æ—¶é—´",{current_time}\n")
            #f.write(f"#EXT-X-GROUP:TITLE=\"æµ‹è¯•æ—¥æœŸ: {current_time}\"\n")
            # 3. éå†ç›´æ’­æºï¼Œå†™å…¥æ¯ä¸ªé¢‘é“ï¼ˆindexè‡ªå¢ä½œä¸ºtvg-idï¼‰
              for index, (name, url) in enumerate(live_sources, start=1):
                # è¿‡æ»¤æ— æ•ˆç›´æ’­æº
                  if not name or not url:
                      logger.warning(f"è·³è¿‡æ— æ•ˆç›´æ’­æºï¼šåç§°={name}, URL={url}")
                      continue
                      
                # logoåœ°å€è§„åˆ™ï¼šhttps://raw.githubusercontent.com/fanmingming/live/main/tv/é¢‘é“åç§°.png
                  logo_url = f"https://raw.githubusercontent.com/fanmingming/live/main/tv/{name}.png"
                
                # å†™å…¥å¸¦æ‰©å±•å­—æ®µçš„é¢‘é“ä¿¡æ¯ï¼ˆç¬¦åˆM3U8æ ‡å‡†ï¼‰
                  f.write(f'#EXTINF:-1 tvg-id="{index}" tvg-name="{name}" tvg-logo="{logo_url}" group-title="{category}",{name}\n')
                # å†™å…¥æ’­æ”¾URL
                  f.write(f'{url}\n')
        
          logger.info(f"å·²ç”Ÿæˆå¸¦æ‰©å±•å­—æ®µçš„M3Uæ–‡ä»¶: {output_path}ï¼ˆå…±{len(live_sources)}ä¸ªé¢‘é“ï¼‰")
      except PermissionError:
          logger.error(f"ç”ŸæˆM3Uæ–‡ä»¶å¤±è´¥ï¼šæ— å†™å…¥æƒé™ï¼ˆè·¯å¾„ï¼š{output_path}ï¼‰")
      except Exception as e:
          logger.error(f"ç”ŸæˆM3Uæ–‡ä»¶å¤±è´¥: {str(e)}", exc_info=True)

   

# ä¸»ç¨‹åº
async def main():
    # è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    #input_file = "input/live_sources.m3u"
    input_file = "output/live_ipv4.m3u"
    #output_file = f"{config.OUTPUT_DIR}/live_sources_sorted_{int(time.time())}.m3u"
    output_file = f"{config.OUTPUT_DIR}/live_sources_ipv4.m3u"
    
    # è§£æM3Uæ–‡ä»¶
    logger.info(f"å¼€å§‹è§£æM3Uæ–‡ä»¶: {input_file}")
    m3u_processor = M3UProcessor()
    live_sources = m3u_processor.parse_m3u(input_file)
    
    if not live_sources:
        logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç›´æ’­æº")
        return
    
    logger.info(f"æ‰¾åˆ° {len(live_sources)} ä¸ªç›´æ’­æº")
    
    # æ‰§è¡Œé€Ÿåº¦æµ‹è¯•
    logger.info("å¼€å§‹é€Ÿåº¦æµ‹è¯•...")
    async with SpeedTester() as tester:
        urls = [source[1] for source in live_sources]
        results = await tester.batch_speed_test(urls)
    
    # æ ¹æ®æµ‹è¯•ç»“æœç›´æ’­æºå»¶æ—¶æ—¶é—´â‰¤650ms çš„ä¿ç•™å¹¶æ’åºï¼Œå…¶ä»–ç›´æ’­æºåˆ é™¤
    url_to_result = {result.url: result for result in results}
    sorted_live_sources = sorted(
    [item for item in live_sources
     if (item[1] in url_to_result) 
     and (url_to_result[item[1]].latency is not None) 
     and (url_to_result[item[1]].latency <= 650)],
    key=lambda x: url_to_result[x[1]].latency
    )

    
    # ç”ŸæˆæŠ¥å‘Š
    success_count = sum(1 for r in results if r.success)
    total_count = len(results)
    
    logger.info(f"é€Ÿåº¦æµ‹è¯•å®Œæˆ: æˆåŠŸ {success_count}/{total_count}")
    logger.info("å‰5ä¸ªæœ€å¿«çš„ç›´æ’­æº:")
    for i, (name, url) in enumerate(sorted_live_sources[:5], 1):
        latency = url_to_result[url].latency
        logger.info(f"{i}. {name} - å»¶è¿Ÿ: {latency:.2f}ms")
    
    # ç”Ÿæˆæ’åºåçš„M3Uæ–‡ä»¶
    m3u_processor.generate_m3u(sorted_live_sources, output_file)
    
    # ç”Ÿæˆé€Ÿåº¦æµ‹è¯•æŠ¥å‘Š
    report_file = f"{config.OUTPUT_DIR}/speed_test_report_log.txt"
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("IPTVç›´æ’­æºé€Ÿåº¦æµ‹è¯•æŠ¥å‘Š\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»æµ‹è¯•æ•°é‡: {total_count}\n")
            f.write(f"æˆåŠŸæ•°é‡: {success_count}\n\n")
            
            f.write("æ’åºåçš„ç›´æ’­æºåˆ—è¡¨:\n")
            for i, (name, url) in enumerate(sorted_live_sources, 1):
                result = url_to_result[url]
                latency = result.latency if result.latency is not None else "N/A"
                status = "æˆåŠŸ" if result.success else f"å¤±è´¥ ({result.error})"
                f.write(f"{i}. {name} - å»¶è¿Ÿ: {latency}ms - çŠ¶æ€: {status}\n")
        
        logger.info(f"å·²ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š: {report_file}")
    except Exception as e:
        logger.error(f"ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())    
